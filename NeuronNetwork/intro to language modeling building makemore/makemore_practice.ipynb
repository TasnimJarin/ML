{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Bigram Model**: Uses one previous character to predict the next character.\n",
        "\n",
        "**Trigram Model**: Uses two previous characters to predict the next character."
      ],
      "metadata": {
        "id": "fT9Fj0l5wKSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('/content/drive/MyDrive/dataSet_for_practice/names.txt', 'r').read().splitlines()"
      ],
      "metadata": {
        "id": "Z-ViogigwNSK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = words[:10]\n",
        "w\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKWxPNlbwN66",
        "outputId": "255de51d-4ed9-4888-b1ce-eec0f9841079"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmaN1xy8wN0B",
        "outputId": "cb5a207e-bf16-46aa-a0a5-1dc118b8bbf2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n"
      ],
      "metadata": {
        "id": "Y6cx7fR95Gx-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **E01:**\n",
        "train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
      ],
      "metadata": {
        "id": "gb7hhrQozUot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_counts = torch.zeros((27,27), dtype = torch.int32)\n",
        "trigram_counts = torch.zeros((27,27,27), dtype = torch.int32)\n",
        "context_counts = torch.zeros((27,27), dtype = torch.int32)\n"
      ],
      "metadata": {
        "id": "OmEnzXRg3Eqp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create character vocabulary\n",
        "chars = sorted(list(set(''.join(words)))) # # Unique characters\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)} #(string-to-index)is a dictionary that maps each character to a unique integer index.\n",
        "stoi['.'] = 0 # Reserve index 0 for padding\n",
        "itos = {i:s for s,i in stoi.items()}# Reverse"
      ],
      "metadata": {
        "id": "tJ0wxYBxzs98"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Populate frequency tables\n",
        "for w in words:\n",
        "    chs = ['.'] + list(w) + ['.']  # Padding\n",
        "    for ch1, ch2 in zip(chs, chs[1:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        bigram_counts[(ix1, ix2)] += 1\n",
        "        context_counts[(ix1,)] += 1  # Context for bigram\n",
        "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "        ix3 = stoi[ch1]\n",
        "        ix4 = stoi[ch2]\n",
        "        ix5 = stoi[ch3]\n",
        "        trigram_counts[(ix3, ix4, ix5)] += 1\n",
        "        context_counts[(ix3, ix4)] += 1  # Context for trigram"
      ],
      "metadata": {
        "id": "QOT6u2h3zF6R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_counts[0,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ0ltHAg5fDI",
        "outputId": "260bc99a-9eb0-480f-eba9-32f78601bcab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
              "        1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
              "         134,  535,  929], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_counts[0,1,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY0nlj2v6Vl6",
        "outputId": "74f8239a-084e-44f3-af04-0070ace67285"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0, 207, 190,  31, 366,  55,  21,  17,  91, 154,  27,  75, 632, 384,\n",
              "        623,  10,  17,   9, 482, 194,  72, 152, 243,   6,  27, 173, 152],\n",
              "       dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P = (bigram_counts+1).float()\n",
        "P /= P.sum(1, keepdim=True)\n",
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSYROtBYKw-Q",
        "outputId": "01573f94-d48d-4fd2-ec44-407181a5b97b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.1192e-05, 1.3759e-01, 4.0767e-02, 4.8129e-02, 5.2745e-02, 4.7785e-02,\n",
              "         1.3038e-02, 2.0898e-02, 2.7293e-02, 1.8465e-02, 7.5577e-02, 9.2452e-02,\n",
              "         4.9064e-02, 7.9195e-02, 3.5777e-02, 1.2321e-02, 1.6095e-02, 2.9008e-03,\n",
              "         5.1154e-02, 6.4130e-02, 4.0830e-02, 2.4641e-03, 1.1759e-02, 9.6070e-03,\n",
              "         4.2109e-03, 1.6719e-02, 2.9008e-02],\n",
              "        [1.9583e-01, 1.6425e-02, 1.5983e-02, 1.3889e-02, 3.0756e-02, 2.0435e-02,\n",
              "         3.9809e-03, 4.9835e-03, 6.8796e-02, 4.8685e-02, 5.1899e-03, 1.6779e-02,\n",
              "         7.4575e-02, 4.8213e-02, 1.6039e-01, 1.8872e-03, 2.4475e-03, 1.7988e-03,\n",
              "         9.6279e-02, 3.2997e-02, 2.0288e-02, 1.1264e-02, 2.4623e-02, 4.7771e-03,\n",
              "         5.3963e-03, 6.0480e-02, 1.2857e-02],\n",
              "        [4.3039e-02, 1.2051e-01, 1.4596e-02, 7.4850e-04, 2.4701e-02, 2.4551e-01,\n",
              "         3.7425e-04, 3.7425e-04, 1.5719e-02, 8.1587e-02, 7.4850e-04, 3.7425e-04,\n",
              "         3.8922e-02, 3.7425e-04, 1.8713e-03, 3.9671e-02, 3.7425e-04, 3.7425e-04,\n",
              "         3.1549e-01, 3.3683e-03, 1.1228e-03, 1.7216e-02, 3.7425e-04, 3.7425e-04,\n",
              "         3.7425e-04, 3.1437e-02, 3.7425e-04],\n",
              "        [2.7536e-02, 2.2928e-01, 2.8098e-04, 1.2082e-02, 5.6196e-04, 1.5510e-01,\n",
              "         2.8098e-04, 8.4293e-04, 1.8685e-01, 7.6426e-02, 1.1239e-03, 8.9070e-02,\n",
              "         3.2874e-02, 2.8098e-04, 2.8098e-04, 1.0705e-01, 5.6196e-04, 3.3717e-03,\n",
              "         2.1635e-02, 1.6859e-03, 1.0115e-02, 1.0115e-02, 2.8098e-04, 2.8098e-04,\n",
              "         1.1239e-03, 2.9503e-02, 1.4049e-03],\n",
              "        [9.3609e-02, 2.3610e-01, 3.6212e-04, 7.2424e-04, 2.7159e-02, 2.3248e-01,\n",
              "         1.0864e-03, 4.7076e-03, 2.1546e-02, 1.2222e-01, 1.8106e-03, 7.2424e-04,\n",
              "         1.1045e-02, 5.6129e-03, 5.7940e-03, 6.8622e-02, 1.8106e-04, 3.6212e-04,\n",
              "         7.6951e-02, 5.4318e-03, 9.0531e-04, 1.6839e-02, 3.2591e-03, 4.3455e-03,\n",
              "         1.8106e-04, 5.7577e-02, 3.6212e-04],\n",
              "        [1.9482e-01, 3.3252e-02, 5.9658e-03, 7.5306e-03, 1.8826e-02, 6.2200e-02,\n",
              "         4.0587e-03, 6.1614e-03, 7.4817e-03, 4.0049e-02, 2.7384e-03, 8.7531e-03,\n",
              "         1.5888e-01, 3.7653e-02, 1.3086e-01, 1.3203e-02, 4.1076e-03, 7.3350e-04,\n",
              "         9.5795e-02, 4.2152e-02, 2.8411e-02, 3.4230e-03, 2.2689e-02, 2.4939e-03,\n",
              "         6.5037e-03, 5.2372e-02, 8.8998e-03],\n",
              "        [8.6910e-02, 2.6073e-01, 1.0730e-03, 1.0730e-03, 1.0730e-03, 1.3305e-01,\n",
              "         4.8283e-02, 2.1459e-03, 2.1459e-03, 1.7275e-01, 1.0730e-03, 3.2189e-03,\n",
              "         2.2532e-02, 1.0730e-03, 5.3648e-03, 6.5451e-02, 1.0730e-03, 1.0730e-03,\n",
              "         1.2339e-01, 7.5107e-03, 2.0386e-02, 1.1803e-02, 1.0730e-03, 5.3648e-03,\n",
              "         1.0730e-03, 1.6094e-02, 3.2189e-03],\n",
              "        [5.5783e-02, 1.6940e-01, 2.0471e-03, 5.1177e-04, 1.0235e-02, 1.7144e-01,\n",
              "         1.0235e-03, 1.3306e-02, 1.8475e-01, 9.7748e-02, 2.0471e-03, 5.1177e-04,\n",
              "         1.6888e-02, 3.5824e-03, 1.4330e-02, 4.2989e-02, 5.1177e-04, 5.1177e-04,\n",
              "         1.0338e-01, 1.5865e-02, 1.6377e-02, 4.4012e-02, 1.0235e-03, 1.3818e-02,\n",
              "         5.1177e-04, 1.6377e-02, 1.0235e-03],\n",
              "        [3.1532e-01, 2.9373e-01, 1.1775e-03, 3.9252e-04, 3.2710e-03, 8.8316e-02,\n",
              "         3.9252e-04, 3.9252e-04, 2.6168e-04, 9.5512e-02, 1.3084e-03, 3.9252e-03,\n",
              "         2.4336e-02, 1.5439e-02, 1.8187e-02, 3.7682e-02, 2.6168e-04, 2.6168e-04,\n",
              "         2.6822e-02, 4.1868e-03, 9.4204e-03, 2.1850e-02, 5.2335e-03, 1.4392e-03,\n",
              "         1.3084e-04, 2.7999e-02, 2.7476e-03],\n",
              "        [1.4046e-01, 1.3797e-01, 6.2613e-03, 2.8768e-02, 2.4876e-02, 9.3299e-02,\n",
              "         5.7536e-03, 2.4199e-02, 5.4152e-03, 4.6819e-03, 4.3434e-03, 2.5158e-02,\n",
              "         7.5925e-02, 2.4143e-02, 1.1998e-01, 3.3224e-02, 3.0460e-03, 2.9896e-03,\n",
              "         4.7947e-02, 7.4289e-02, 3.0573e-02, 6.2049e-03, 1.5230e-02, 5.0767e-04,\n",
              "         5.0767e-03, 4.3998e-02, 1.5681e-02],\n",
              "        [2.4599e-02, 5.0359e-01, 6.8329e-04, 1.7082e-03, 1.7082e-03, 1.5067e-01,\n",
              "         3.4165e-04, 3.4165e-04, 1.5716e-02, 4.0998e-02, 1.0249e-03, 1.0249e-03,\n",
              "         3.4165e-03, 2.0499e-03, 1.0249e-03, 1.6399e-01, 6.8329e-04, 3.4165e-04,\n",
              "         4.0998e-03, 2.7332e-03, 1.0249e-03, 6.9354e-02, 2.0499e-03, 2.3915e-03,\n",
              "         3.4165e-04, 3.7581e-03, 3.4165e-04],\n",
              "        [7.1837e-02, 3.4182e-01, 5.9207e-04, 5.9207e-04, 5.9207e-04, 1.7683e-01,\n",
              "         3.9471e-04, 1.9736e-04, 6.0785e-02, 1.0065e-01, 5.9207e-04, 4.1445e-03,\n",
              "         2.7630e-02, 1.9736e-03, 5.3286e-03, 6.8088e-02, 1.9736e-04, 1.9736e-04,\n",
              "         2.1709e-02, 1.8946e-02, 3.5524e-03, 1.0065e-02, 5.9207e-04, 6.9074e-03,\n",
              "         1.9736e-04, 7.4995e-02, 5.9207e-04],\n",
              "        [9.4029e-02, 1.8763e-01, 3.7898e-03, 1.8591e-03, 9.9392e-03, 2.0894e-01,\n",
              "         1.6446e-03, 5.0054e-04, 1.4301e-03, 1.7740e-01, 5.0054e-04, 1.7876e-03,\n",
              "         9.6246e-02, 4.3618e-03, 1.0726e-03, 4.9553e-02, 1.1441e-03, 2.8602e-04,\n",
              "         1.3586e-03, 6.7930e-03, 5.5774e-03, 2.3239e-02, 5.2199e-03, 1.2156e-03,\n",
              "         7.1505e-05, 1.1362e-01, 7.8656e-04],\n",
              "        [7.7523e-02, 3.8851e-01, 1.6944e-02, 7.7973e-03, 3.7487e-03, 1.2281e-01,\n",
              "         2.9990e-04, 1.4995e-04, 8.9969e-04, 1.8848e-01, 1.1996e-03, 2.9990e-04,\n",
              "         8.9969e-04, 2.5341e-02, 3.1489e-03, 6.7926e-02, 5.8480e-03, 1.4995e-04,\n",
              "         1.4695e-02, 5.3981e-03, 7.4974e-04, 2.0993e-02, 5.9979e-04, 4.4984e-04,\n",
              "         1.4995e-04, 4.3185e-02, 1.7994e-03],\n",
              "        [3.6853e-01, 1.6225e-01, 4.9036e-04, 1.1660e-02, 3.8411e-02, 7.4098e-02,\n",
              "         6.5381e-04, 1.4929e-02, 1.4711e-03, 9.4039e-02, 2.4518e-03, 3.2146e-03,\n",
              "         1.0679e-02, 1.0897e-03, 1.0390e-01, 2.7079e-02, 3.2690e-04, 1.6345e-04,\n",
              "         2.4518e-03, 1.5201e-02, 2.4191e-02, 5.2850e-03, 3.0511e-03, 6.5381e-04,\n",
              "         3.8139e-04, 2.5390e-02, 7.9547e-03],\n",
              "        [1.0752e-01, 1.8842e-02, 1.7711e-02, 1.4445e-02, 2.3992e-02, 1.6706e-02,\n",
              "         4.3964e-03, 5.6526e-03, 2.1605e-02, 8.7929e-03, 2.1354e-03, 8.6673e-03,\n",
              "         7.7880e-02, 3.2910e-02, 3.0298e-01, 1.4571e-02, 1.2059e-02, 5.0245e-04,\n",
              "         1.3315e-01, 6.3434e-02, 1.4948e-02, 3.4669e-02, 2.2233e-02, 1.4445e-02,\n",
              "         5.7782e-03, 1.3064e-02, 6.9087e-03],\n",
              "        [3.2289e-02, 1.9943e-01, 2.8490e-03, 1.8993e-03, 9.4967e-04, 1.8803e-01,\n",
              "         1.8993e-03, 9.4967e-04, 1.9468e-01, 5.8879e-02, 1.8993e-03, 1.8993e-03,\n",
              "         1.6144e-02, 1.8993e-03, 1.8993e-03, 5.6980e-02, 3.7987e-02, 9.4967e-04,\n",
              "         1.4435e-01, 1.6144e-02, 1.7094e-02, 4.7483e-03, 9.4967e-04, 9.4967e-04,\n",
              "         9.4967e-04, 1.2346e-02, 9.4967e-04],\n",
              "        [9.6990e-02, 4.6823e-02, 3.3445e-03, 3.3445e-03, 3.3445e-03, 6.6890e-03,\n",
              "         3.3445e-03, 3.3445e-03, 3.3445e-03, 4.6823e-02, 3.3445e-03, 3.3445e-03,\n",
              "         6.6890e-03, 1.0033e-02, 3.3445e-03, 1.0033e-02, 3.3445e-03, 3.3445e-03,\n",
              "         6.6890e-03, 1.0033e-02, 3.3445e-03, 6.9231e-01, 3.3445e-03, 1.3378e-02,\n",
              "         3.3445e-03, 3.3445e-03, 3.3445e-03],\n",
              "        [1.0827e-01, 1.8520e-01, 3.3001e-03, 7.8573e-03, 1.4772e-02, 1.3342e-01,\n",
              "         7.8573e-04, 6.0501e-03, 9.5859e-03, 2.3839e-01, 2.0429e-03, 7.1502e-03,\n",
              "         3.2529e-02, 1.2807e-02, 1.1079e-02, 6.8359e-02, 1.1786e-03, 1.3357e-03,\n",
              "         3.3472e-02, 1.5007e-02, 1.6422e-02, 1.9879e-02, 6.3644e-03, 1.7286e-03,\n",
              "         3.1429e-04, 6.0816e-02, 1.8858e-03],\n",
              "        [1.4386e-01, 1.4779e-01, 2.7050e-03, 7.5003e-03, 1.2296e-03, 1.0882e-01,\n",
              "         3.6887e-04, 3.6887e-04, 1.5812e-01, 8.4225e-02, 3.6887e-04, 1.0205e-02,\n",
              "         3.4428e-02, 1.1189e-02, 3.0739e-03, 6.5413e-02, 6.3937e-03, 2.4591e-04,\n",
              "         6.8855e-03, 5.6806e-02, 9.4184e-02, 2.2870e-02, 1.8443e-03, 3.0739e-03,\n",
              "         1.2296e-04, 2.6558e-02, 1.3525e-03],\n",
              "        [8.6475e-02, 1.8367e-01, 3.5733e-04, 3.2160e-03, 1.7867e-04, 1.2810e-01,\n",
              "         5.3600e-04, 5.3600e-04, 1.1578e-01, 9.5230e-02, 7.1467e-04, 1.7867e-04,\n",
              "         2.4120e-02, 8.9334e-04, 4.1093e-03, 1.1935e-01, 1.7867e-04, 1.7867e-04,\n",
              "         6.3070e-02, 6.4320e-03, 6.7000e-02, 1.4115e-02, 2.8587e-03, 2.1440e-03,\n",
              "         5.3600e-04, 6.1104e-02, 1.8939e-02],\n",
              "        [4.9336e-02, 5.1866e-02, 3.2891e-02, 3.2891e-02, 4.3327e-02, 5.3763e-02,\n",
              "         6.3251e-03, 1.5180e-02, 1.8659e-02, 3.8583e-02, 4.7438e-03, 2.9728e-02,\n",
              "         9.5509e-02, 4.9020e-02, 8.7287e-02, 3.4788e-03, 5.3763e-03, 3.4788e-03,\n",
              "         1.3125e-01, 1.5022e-01, 2.6249e-02, 1.2650e-03, 1.2018e-02, 2.7514e-02,\n",
              "         1.1069e-02, 4.4276e-03, 1.4548e-02],\n",
              "        [3.4231e-02, 2.4731e-01, 7.6923e-04, 3.8462e-04, 7.6923e-04, 2.1885e-01,\n",
              "         3.8462e-04, 3.8462e-04, 7.6923e-04, 3.5077e-01, 3.8462e-04, 1.5385e-03,\n",
              "         5.7692e-03, 3.8462e-04, 3.4615e-03, 5.9231e-02, 3.8462e-04, 3.8462e-04,\n",
              "         1.8846e-02, 3.8462e-04, 3.8462e-04, 3.0769e-03, 3.0769e-03, 3.8462e-04,\n",
              "         3.8462e-04, 4.6923e-02, 3.8462e-04],\n",
              "        [5.4393e-02, 2.9393e-01, 2.0921e-03, 1.0460e-03, 9.4142e-03, 1.5690e-01,\n",
              "         3.1381e-03, 2.0921e-03, 2.5105e-02, 1.5586e-01, 1.0460e-03, 7.3222e-03,\n",
              "         1.4644e-02, 3.1381e-03, 6.1715e-02, 3.8703e-02, 1.0460e-03, 1.0460e-03,\n",
              "         2.4059e-02, 2.1967e-02, 9.4142e-03, 2.7197e-02, 1.0460e-03, 3.1381e-03,\n",
              "         1.0460e-03, 7.7406e-02, 2.0921e-03],\n",
              "        [2.2790e-01, 1.4365e-01, 2.7624e-03, 6.9061e-03, 8.2873e-03, 5.1105e-02,\n",
              "         5.5249e-03, 1.3812e-03, 2.7624e-03, 1.4227e-01, 1.3812e-03, 1.3812e-03,\n",
              "         5.5249e-02, 2.7624e-03, 2.7624e-03, 5.8011e-02, 1.3812e-03, 1.3812e-03,\n",
              "         1.3812e-03, 4.4199e-02, 9.8066e-02, 8.2873e-03, 1.3812e-03, 5.5249e-03,\n",
              "         5.3867e-02, 4.2818e-02, 2.7624e-02],\n",
              "        [2.0484e-01, 2.1871e-01, 2.8563e-03, 1.1833e-02, 2.7849e-02, 3.0807e-02,\n",
              "         1.3261e-03, 3.1623e-03, 2.3462e-03, 1.9688e-02, 2.4482e-03, 8.8748e-03,\n",
              "         1.1272e-01, 1.5199e-02, 1.8637e-01, 2.7747e-02, 1.6322e-03, 7.1407e-04,\n",
              "         2.9787e-02, 4.1008e-02, 1.0711e-02, 1.4485e-02, 1.0915e-02, 5.1005e-04,\n",
              "         2.9583e-03, 2.4482e-03, 8.0588e-03],\n",
              "        [6.6392e-02, 3.5505e-01, 2.0619e-03, 1.2371e-03, 1.2371e-03, 1.5423e-01,\n",
              "         4.1237e-04, 8.2474e-04, 1.8144e-02, 1.5052e-01, 1.2371e-03, 1.2371e-03,\n",
              "         5.1134e-02, 1.4845e-02, 2.0619e-03, 4.5773e-02, 1.2371e-03, 4.1237e-04,\n",
              "         1.3608e-02, 2.0619e-03, 2.0619e-03, 3.0515e-02, 1.2371e-03, 1.6495e-03,\n",
              "         8.2474e-04, 6.1031e-02, 1.8969e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(10):\n",
        "    ix = 0\n",
        "    out = []\n",
        "    while True:\n",
        "        p = P[ix]\n",
        "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "        if ix >= len(itos):\n",
        "        #Handle the case when sampling produces the padding character or any character ouside of valid itos range(0-26)\n",
        "            break # Break out of the while loop if sampling produces a padding character or any invalid characters for itos dict\n",
        "        out.append(itos[ix])\n",
        "        if ix == 0:\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    print(''.join(out))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whOpaFpGK7Vo",
        "outputId": "c2a3af25-e1b4-4536-ad81-6be074d3e900"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "junide.\n",
            "janasah.\n",
            "p.\n",
            "cony.\n",
            "a.\n",
            "nn.\n",
            "kohin.\n",
            "tolian.\n",
            "juee.\n",
            "ksahnaauranilevias.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P1 = (trigram_counts+1).float()\n",
        "P1 /= P1.sum(2, keepdim=True)\n",
        "assert P1[0, 0].sum() == 1"
      ],
      "metadata": {
        "id": "m9K12H7QNNkE"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h91ESE_bAsBI",
        "outputId": "81f1acc8-a41d-4648-a2b0-6a24dc290854"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 27, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    ix1 = 0\n",
        "    ix2 = 0\n",
        "    out = []\n",
        "    while True:\n",
        "        p = P1[ix1, ix2]\n",
        "        ix1 = ix2\n",
        "        ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "        if ix >= len(itos):\n",
        "            break\n",
        "        out.append(itos[ix2])\n",
        "        if ix2 == 0:\n",
        "            break\n",
        "    print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OrZ7KmL7-BV",
        "outputId": "e59e2585-47fb-4dda-ed88-e9f4148da10d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "junide.\n",
            "ilyasid.\n",
            "prelay.\n",
            "ocin.\n",
            "fairritoper.\n",
            "sathen.\n",
            "dannaaryanileniassibduinrwin.\n",
            "lessiyanayla.\n",
            "te.\n",
            "farmumthyfortumj.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate loss which is negative log likelihood:"
      ],
      "metadata": {
        "id": "3npeeaMXzXJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_likelihood = 0.0\n",
        "n = 0\n",
        "\n",
        "for w in words:\n",
        "    chs = ['.'] + list(w) + ['.']\n",
        "    for ch1, ch2 in zip(chs, chs[1:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        pro = P[ix1,ix2]\n",
        "        logpro = torch.log(pro)\n",
        "        log_likelihood += logpro\n",
        "        n += 1\n",
        "        #print(f'{ch1}{ch2} : {pro:.4f} , {logpro: .4f}')\n",
        "\n",
        "\n",
        "\n",
        "print(f'{log_likelihood=}')\n",
        "nll = -log_likelihood\n",
        "print(f'{nll=}')\n",
        "bigram_loss = nll/n\n",
        "print(f'Bigram Model: {bigram_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPusc3_YYCjQ",
        "outputId": "282f2eb7-4c4b-4ae1-8719-a6f6129d01e4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_likelihood=tensor(-559951.5625)\n",
            "nll=tensor(559951.5625)\n",
            "Bigram Model: 2.4543561935424805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_likelihood1 = 0.0\n",
        "n1 = 0\n",
        "\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "        ix3 = stoi[ch1]\n",
        "        ix4 = stoi[ch2]\n",
        "        ix5 = stoi[ch3]\n",
        "        pro1 = P1[ix3, ix4, ix5]\n",
        "        logpro1 = torch.log(pro1)\n",
        "        log_likelihood1 += logpro1\n",
        "        n1 += 1\n",
        "        #print(f'{ch1}{ch2}{ch3} : {pro1:.4f} , {logpro1: .4f}')\n",
        "\n",
        "\n",
        "\n",
        "print(f'{log_likelihood1=}')\n",
        "nll1 = -log_likelihood1\n",
        "print(f'{nll1=}')\n",
        "trigram_loss = nll1/n1\n",
        "print(f'Trigram Model: {trigram_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSRFymRFZEb7",
        "outputId": "494c3515-ef0b-4973-aad0-564e66733c4f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_likelihood1=tensor(-410414.9688)\n",
            "nll1=tensor(410414.9688)\n",
            "Trigram Model: 2.092747449874878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare performance\n",
        "if trigram_loss < bigram_loss:\n",
        "    print(\"Trigram model performs better (lower loss).\")\n",
        "else:\n",
        "    print(\"Bigram model generalizes better (lower loss).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aCVwLN6vqZB",
        "outputId": "9aefafcf-7376-49e3-e67f-ab9265cf87b9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigram model performs better (lower loss).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NN Approach"
      ],
      "metadata": {
        "id": "KSQhY8RP94Ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create training set of trigrams, packing 1st and 2nd char as inputs and 3rd char as output:"
      ],
      "metadata": {
        "id": "woxDv-goKHVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "zaVG2PXf95Dl"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs, ys = [], []\n",
        "\n",
        "for w in words[:1]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    xs.append((stoi[ch1], stoi[ch2]))\n",
        "    ys.append(stoi[ch3])\n",
        "    print(f'{ch1}[{stoi[ch2]}], {ch2}[{stoi[ch2]}], {ch3}[{stoi[ch3]}]')\n",
        "\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('number of examples: ', num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ycr4aIN97JG",
        "outputId": "728ab41d-5ebf-4700-b0eb-7f7366c16030"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".[5], e[5], m[13]\n",
            "e[13], m[13], m[13]\n",
            "m[13], m[13], a[1]\n",
            "m[1], a[1], .[0]\n",
            "number of examples:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = F.one_hot(xs, num_classes=27)\n",
        "print(xenc), xenc.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMz5d67n-TxN",
        "outputId": "77a12607-58ef-4c9d-cd99-c9381aca7d96"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0, 0, 0, 0]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, torch.Size([4, 2, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs.shape, ys.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyWmSqwN_Agu",
        "outputId": "af88b934-4c4c-4f5f-e4da-221a8f4b685d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 2]), torch.Size([4]))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = xenc.reshape(4, -1).float()\n",
        "xenc.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH57twuv_MaH",
        "outputId": "e24371e5-2b1f-41dd-cc7d-61344b4239b1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 54])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(xenc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "fYaiN21e_OMe",
        "outputId": "bb5d2267-428c-4e41-dea1-b6f0248a7766"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e285f331090>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27*2, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "hyh72zc0_R-3"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = xenc @ W\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdims=True)\n",
        "loss = -probs[torch.arange(4), ys].log().mean()\n",
        "loss.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXZJiRAv_T0Q",
        "outputId": "2a8ca983-2f44-438f-e3af-98a1c93e4ae9"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.095324993133545"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W.grad = None\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "uLP4kqi6_V9P"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's put everything together:"
      ],
      "metadata": {
        "id": "guv3UIn-_ZHG"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs, ys = [], []\n",
        "\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    xs.append((stoi[ch1], stoi[ch2]))\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27*2, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "BKCu-9zn_anW"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(100):\n",
        "  xenc = F.one_hot(xs, num_classes=27)\n",
        "  xenc = xenc.reshape(len(xenc), -1).float()\n",
        "\n",
        "  logits = xenc @ W\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  loss = -probs[torch.arange(len(xenc)), ys].log().mean()\n",
        "\n",
        "  print(loss.item())\n",
        "\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  W.data += -50 * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy-eqSuQ_d3X",
        "outputId": "4842d5a3-39a9-4959-a16b-0c99e9a515af"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.186270713806152\n",
            "3.3573689460754395\n",
            "3.042151689529419\n",
            "2.871455430984497\n",
            "2.7671945095062256\n",
            "2.694681406021118\n",
            "2.6390926837921143\n",
            "2.5949814319610596\n",
            "2.5590028762817383\n",
            "2.529222011566162\n",
            "2.5042338371276855\n",
            "2.483072280883789\n",
            "2.464961051940918\n",
            "2.4493141174316406\n",
            "2.435654401779175\n",
            "2.423619031906128\n",
            "2.412919759750366\n",
            "2.4033381938934326\n",
            "2.394700288772583\n",
            "2.386871099472046\n",
            "2.379739999771118\n",
            "2.3732175827026367\n",
            "2.3672287464141846\n",
            "2.3617119789123535\n",
            "2.3566133975982666\n",
            "2.3518879413604736\n",
            "2.34749698638916\n",
            "2.343406915664673\n",
            "2.3395884037017822\n",
            "2.3360161781311035\n",
            "2.332667350769043\n",
            "2.3295230865478516\n",
            "2.3265652656555176\n",
            "2.3237786293029785\n",
            "2.3211495876312256\n",
            "2.3186655044555664\n",
            "2.3163154125213623\n",
            "2.314089059829712\n",
            "2.3119773864746094\n",
            "2.3099722862243652\n",
            "2.3080661296844482\n",
            "2.3062520027160645\n",
            "2.3045237064361572\n",
            "2.302875518798828\n",
            "2.301302194595337\n",
            "2.2997987270355225\n",
            "2.29836106300354\n",
            "2.2969844341278076\n",
            "2.2956652641296387\n",
            "2.294400930404663\n",
            "2.293187141418457\n",
            "2.2920210361480713\n",
            "2.290900468826294\n",
            "2.2898223400115967\n",
            "2.2887845039367676\n",
            "2.2877845764160156\n",
            "2.286820411682129\n",
            "2.2858901023864746\n",
            "2.2849926948547363\n",
            "2.284125328063965\n",
            "2.2832868099212646\n",
            "2.2824764251708984\n",
            "2.281691551208496\n",
            "2.2809317111968994\n",
            "2.280195951461792\n",
            "2.27948260307312\n",
            "2.2787907123565674\n",
            "2.2781200408935547\n",
            "2.277468204498291\n",
            "2.2768356800079346\n",
            "2.2762207984924316\n",
            "2.275623083114624\n",
            "2.2750420570373535\n",
            "2.2744765281677246\n",
            "2.2739264965057373\n",
            "2.273391008377075\n",
            "2.272869348526001\n",
            "2.2723608016967773\n",
            "2.271864891052246\n",
            "2.2713818550109863\n",
            "2.2709107398986816\n",
            "2.270451307296753\n",
            "2.2700021266937256\n",
            "2.269564390182495\n",
            "2.269136428833008\n",
            "2.2687184810638428\n",
            "2.268310308456421\n",
            "2.267911195755005\n",
            "2.2675209045410156\n",
            "2.267139196395874\n",
            "2.266765832901001\n",
            "2.2664010524749756\n",
            "2.266043186187744\n",
            "2.265693426132202\n",
            "2.265350580215454\n",
            "2.2650153636932373\n",
            "2.2646868228912354\n",
            "2.2643649578094482\n",
            "2.2640492916107178\n",
            "2.263740062713623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems like loss is a bit lower than\n",
        "\n",
        "bigram but not as low as count method ðŸ¤”\n",
        "\n",
        "**Sampling from net:**"
      ],
      "metadata": {
        "id": "EVGhUyul_j0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finally, sample from the 'neural net' model\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  out = []\n",
        "  ix1, ix2 = 0, 0\n",
        "  while True:\n",
        "    xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=27).float()\n",
        "    xenc = xenc.reshape((1, -1))\n",
        "    logits = xenc @ W\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdims=True)\n",
        "\n",
        "    ix1 = ix2\n",
        "    ix2 = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix2])\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em5DroYg_ohW",
        "outputId": "604361b5-2893-4d7b-f44e-d39e193a5e93"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aunide.\n",
            "aliasad.\n",
            "ushfay.\n",
            "ainn.\n",
            "aui.\n",
            "ritoleras.\n",
            "get.\n",
            "adannaauranileniassibdainrwi.\n",
            "ol.\n",
            "seisiely.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **E02:**\n",
        " split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?"
      ],
      "metadata": {
        "id": "vqGQo1NVwBoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dev Set (10%)\n",
        "words[int(0.8 * n):int(0.9 * n)]\n",
        "Starts after 80% (from index 0.8 * n)\n",
        "Ends at 90% (up to index 0.9 * n)\n",
        "This results in 10% of the dataset\n",
        "\n",
        "test Set (10%)\n",
        "words[int(0.9 * n):]\n",
        "Starts after 90% (from index 0.9 * n)\n",
        "Ends at the last index of words, which includes the final 10% of data\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7du-JZRixQ3U",
        "outputId": "562ca06b-34df-4855-8fee-4aed69713748"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nDev Set (10%)\\nwords[int(0.8 * n):int(0.9 * n)]\\nStarts after 80% (from index 0.8 * n)\\nEnds at 90% (up to index 0.9 * n)\\nThis results in 10% of the dataset\\n\\ntest Set (10%)\\nwords[int(0.9 * n):]\\nStarts after 90% (from index 0.9 * n)\\nEnds at the last index of words, which includes the final 10% of data\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ],
      "metadata": {
        "id": "J1WPApj6Ksly"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build the data set\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def create_dataset(word, ngram=2):\n",
        "  xs, ys = [], []\n",
        "  for w in word:\n",
        "    chs = ['.'] + list(w) + ['.']  # Add start & end tokens\n",
        "    for i in range(len(chs) - (ngram - 1)):\n",
        "      context = chs[i:i + ngram]  # Extract n-gram context\n",
        "      ix1 = [stoi[ch] for ch in context[:-1]]  # Input indices\n",
        "      ix2 = stoi[context[-1]]  # Target index\n",
        "      xs.append(ix1 if ngram > 2 else ix1[0])  # Flatten for bigram\n",
        "      ys.append(ix2)\n",
        "\n",
        "  xs = torch.tensor(xs)\n",
        "  ys = torch.tensor(ys)\n",
        "  print(xs.shape, ys.shape)\n",
        "  return torch.tensor(xs), torch.tensor(ys)\n",
        "\n",
        "\n",
        "import random\n",
        "# Split dataset into 80% train, 10% dev, 10% test\n",
        "random.seed(42)\n",
        "random.shuffle(words)  # Shuffle the dataset\n",
        "n = len(words)\n",
        "train_words = words[:int(0.8 * n)]\n",
        "dev_words = words[int(0.8 * n):int(0.9 * n)]\n",
        "test_words = words[int(0.9 * n):]\n",
        "\n",
        "\n",
        "# Create datasets\n",
        "xs_train, ys_train = create_dataset(train_words, ngram=2)  # Bigram training set\n",
        "xs_dev, ys_dev = create_dataset(dev_words, ngram=2)  # Dev set\n",
        "xs_test, ys_test = create_dataset(test_words, ngram=2)  # Test set\n",
        "\n",
        "xs_train_tri, ys_train_tri = create_dataset(train_words, ngram=3)  # Trigram training set\n",
        "xs_dev_tri, ys_dev_tri = create_dataset(dev_words, ngram=3)  # Dev set\n",
        "xs_test_tri, ys_test_tri = create_dataset(test_words, ngram=3)  # Test set\n",
        "\n",
        "print(f\"Train set size: {len(xs_train)} examples\")\n",
        "print(f\"Dev set size: {len(xs_dev)} examples\")\n",
        "print(f\"Test set size: {len(xs_test)} examples\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW6YQHAQK7Nk",
        "outputId": "a3e4dcc8-4224-418e-bd6a-2db0354dc646"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182580]) torch.Size([182580])\n",
            "torch.Size([22767]) torch.Size([22767])\n",
            "torch.Size([22799]) torch.Size([22799])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-107-1790f5a3b243>:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(xs), torch.tensor(ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([156954, 2]) torch.Size([156954])\n",
            "torch.Size([19564, 2]) torch.Size([19564])\n",
            "torch.Size([19595, 2]) torch.Size([19595])\n",
            "Train set size: 182580 examples\n",
            "Dev set size: 22767 examples\n",
            "Test set size: 22799 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize network\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W_bigram = torch.randn((27, 27), generator=g, requires_grad=True)\n",
        "W_trigram = torch.randn((27, 27, 27), generator=g, requires_grad=True)  # 3D for trigram"
      ],
      "metadata": {
        "id": "ikjxbXYFRuS3"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_trigram.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU1q_yFMTP8z",
        "outputId": "57a72c11-f502-40ac-a002-0a3ce5c57445"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 27, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ngram(xs, ys, W, ngram, epochs=10, lr=50):\n",
        "    for k in range(epochs):\n",
        "        if ngram == 2:\n",
        "            xenc = F.one_hot(xs, num_classes=27).float()\n",
        "            logits = (xenc @ W).squeeze()\n",
        "        elif ngram == 3:\n",
        "          xs = xs.reshape(-1, 2)\n",
        "          ix1, ix2 = xs[:, 0], xs[:, 1]\n",
        "          xenc = F.one_hot(torch.stack([ix1, ix2], dim=-1), num_classes=27).float()\n",
        "          xenc = xenc.reshape((xenc.shape[0], -1))\n",
        "          logits = xenc @ W\n",
        "\n",
        "\n",
        "        else:\n",
        "          raise ValueError(\"Only supports bigram (ngram=2) or trigram (ngram=3)\")\n",
        "\n",
        "        counts = logits.exp()\n",
        "        probs = counts / counts.sum(1, keepdims=True)  # Convert to probabilities\n",
        "        loss = -probs[torch.arange(xs.shape[0]), ys].log().mean() + 0.01 * (W**2).mean()\n",
        "        print(f\"Epoch {k+1}, Loss: {loss.item()}\")\n",
        "\n",
        "        W.grad = None\n",
        "        loss.backward()\n",
        "        W.data += -lr * W.grad  # Update weights\n",
        "    return W\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DACJE9kjRyw8"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Bigram Model\n",
        "print(\"\\nTraining Bigram Model:\")\n",
        "W_bigram = train_ngram(xs_train, ys_train, W_bigram,ngram=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJoUitJGPh8N",
        "outputId": "dadfba72-930e-409e-ba27-dee0fa04cdd0"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Bigram Model:\n",
            "Epoch 1, Loss: 2.521151304244995\n",
            "Epoch 2, Loss: 2.5197243690490723\n",
            "Epoch 3, Loss: 2.5183732509613037\n",
            "Epoch 4, Loss: 2.5170929431915283\n",
            "Epoch 5, Loss: 2.5158777236938477\n",
            "Epoch 6, Loss: 2.514724016189575\n",
            "Epoch 7, Loss: 2.51362681388855\n",
            "Epoch 8, Loss: 2.5125832557678223\n",
            "Epoch 9, Loss: 2.5115888118743896\n",
            "Epoch 10, Loss: 2.510641098022461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Trigram Model\n",
        "print(\"\\nTraining Trigram Model:\")\n",
        "W_trigram = train_ngram(xs_train_tri, ys_train_tri, W_trigram, ngram=3)"
      ],
      "metadata": {
        "id": "ONP2KV5-ITOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Function\n",
        "def evaluate(xs, ys, W):\n",
        "    xenc = F.one_hot(xs, num_classes=27).float()\n",
        "    logits = (xenc @ W).squeeze()\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdims=True)\n",
        "    loss = -probs[torch.arange(xs.nelement()), ys].log().mean().item()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "9b4mf1HwUN32"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on dev and test splits\n",
        "print(\"\\nEvaluating Bigram Model:\")\n",
        "dev_loss_bigram = evaluate(xs_dev, ys_dev, W_bigram)\n",
        "test_loss_bigram = evaluate(xs_test, ys_test, W_bigram)\n",
        "print(f\"Bigram Dev Loss: {dev_loss_bigram}\")\n",
        "print(f\"Bigram Test Loss: {test_loss_bigram}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edfaobz7UOiZ",
        "outputId": "ed29c890-ca1f-4b68-e1bd-a6f56d4787e1"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Bigram Model:\n",
            "Bigram Dev Loss: 2.688514471054077\n",
            "Bigram Test Loss: 2.6892077922821045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nEvaluating Trigram Model:\")\n",
        "dev_loss_trigram = evaluate(xs_dev_tri, ys_dev_tri, W_trigram)\n",
        "test_loss_trigram = evaluate(xs_test_tri, ys_test_tri, W_trigram)\n",
        "print(f\"Trigram Dev Loss: {dev_loss_trigram}\")\n",
        "print(f\"Trigram Test Loss: {test_loss_trigram}\")"
      ],
      "metadata": {
        "id": "SSH59-_OVRQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **E03:**\n",
        " use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?"
      ],
      "metadata": {
        "id": "YMohkO0aYwMX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5kTeJKXpYySD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}